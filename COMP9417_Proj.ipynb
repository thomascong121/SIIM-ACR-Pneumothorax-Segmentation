{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport numpy as np\nimport pandas as pd\nimport gc\nimport keras\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.losses import binary_crossentropy\n\nimport glob, shutil,os,random,sys\nfrom PIL import Image\n\nfrom tensorflow import reduce_sum\nfrom keras.backend import pow\nfrom keras import Model\nfrom keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten,LeakyReLU\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import  ModelCheckpoint,Callback,LearningRateScheduler\nimport keras.callbacks as callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nimport skimage.io as io\nimport skimage.transform as trans\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\nimport cv2\n\nfrom tqdm import tqdm_notebook\n\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\ntf.set_random_seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\n!pip install -U efficientnet==0.0.4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyper parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"h,w,batch_size = 256,256,16\nimage_size = 256\nepochs = 5\npath_for_mask = \"../input/masks/\"\npath_for_train = \"../input/train/\"\npath_for_test = \"../input/test/\"\nU_net_model = False\nU_net_PP_model = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mask Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract Image Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_mask_fn = glob.glob(path_for_mask + \"*\")\nmask_df = pd.DataFrame()\nmask_df['file_names'] = all_mask_fn\nmask_df['mask_percentage'] = 0\nmask_df.set_index('file_names',inplace=True)\nfor fn in all_mask_fn:\n    mask_df.loc[fn,'mask_percentage'] = np.array(Image.open(fn)).sum()/(256*256*255)\n    \nmask_df.reset_index(inplace=True)\nmask_df['labels'] = 0\nmask_df.loc[mask_df.mask_percentage>0,'labels'] = 1\n\nall_train_fn = glob.glob(path_for_train + '*')\ntotal_samples = len(all_train_fn)\nidx = np.arange(total_samples)#generate an array from 0 to len(total samples)\ntrain_fn,val_fn = train_test_split(all_train_fn,stratify=mask_df.labels,test_size=0.1,random_state=10)\n\nmasks_train_fn = [fn.replace('./train','./masks') for fn in train_fn]    \nmasks_val_fn = [fn.replace('./train','./masks') for fn in val_fn]\n\nprint('No. of train files %d and labels %d'%(len(train_fn),len(masks_train_fn)))\nprint('No. of val files %d and lable %d'%(len(val_fn),len(masks_val_fn)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate Train, validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mask = []\nval_mask = []\nfor i in train_fn:\n    img_label = i.split(\"/\")[-1]\n    mask_path = path_for_mask + img_label\n    if(mask_path in all_mask_fn):\n        train_mask.append(mask_path)\n    else:\n        \"Train mask not found\"\n        \nfor i in val_fn:\n    img_label = i.split(\"/\")[-1]\n    mask_path = path_for_mask + img_label\n    if(mask_path in all_mask_fn):\n        val_mask.append(mask_path)\n    else:\n        \"Valid mask not found\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate IOU(as model accrucy)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\ndef get_iou_vector(A, B):\n    # Numpy version    \n    batch_size = A.shape[0]\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        # deal with empty mask first\n        if true == 0:\n            metric += (pred == 0)\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection / union\n        dice = 2 * iou\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        #iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n        \n        metric += dice\n        \n    # teake the average over all images in batch\n    metric /= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image Augmentation Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n)\n\nAUGMENTATIONS_TRAIN = Compose([\n    HorizontalFlip(p=0.5),\n    OneOf([\n        RandomContrast(),\n        RandomGamma(),\n        RandomBrightness(),\n         ], p=0.3),\n    OneOf([\n        ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        GridDistortion(),\n        OpticalDistortion(distort_limit=2, shift_limit=0.5),\n        ], p=0.3),\n    RandomSizedCrop(min_max_height=(156, 256), height=h, width=w,p=0.25),\n    ToFloat(max_value=1)\n],p=1)\n\n\nAUGMENTATIONS_TEST = Compose([\n    ToFloat(max_value=1)\n],p=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define Data Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, train_im_path=train_fn,train_mask_path=train_mask,\n                 augmentations=None, batch_size=batch_size,img_size=256, n_channels=3, shuffle=True):\n        'Initialization'\n        self.batch_size = batch_size\n        \n        self.train_im_path = train_im_path#list of training image\n        self.train_mask_path = train_mask_path#list of trainig mask\n\n        self.img_size = img_size\n        \n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.augment = augmentations\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return len(self.train_im_path) // self.batch_size\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:min((index+1)*self.batch_size,len(self.train_im_path))]\n\n        # Find list of IDs\n        list_IDs_im = [self.train_im_path[k] for k in indexes]\n\n        # Generate data\n        X, y = self.data_generation(list_IDs_im)\n\n        if self.augment is None:\n            return X,np.array(y)/255\n        else:            \n            im,mask = [],[]   \n            for x,y in zip(X,y):\n                augmented = self.augment(image=x, mask=y)\n                im.append(augmented['image'])\n                mask.append(augmented['mask'])\n            return np.array(im),np.array(mask)/255\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.train_im_path))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, list_IDs_im):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((len(list_IDs_im),self.img_size,self.img_size, self.n_channels))\n        y = np.empty((len(list_IDs_im),self.img_size,self.img_size, 1))\n\n        # Generate data\n        for i, im_path in enumerate(list_IDs_im):\n            \n            im = np.array(Image.open(im_path))\n            imgNum = im_path.split(\"train/\")[1]\n            mask = np.array(Image.open(path_for_mask+imgNum))\n      \n            if len(im.shape)==2:\n                im = np.expand_dims(im,axis=2)\n            X[i,] = im\n\n            mask = np.expand_dims(mask,axis=2)\n            y[i,] = mask\n            y[y>0] = 255\n        return np.uint8(X),np.uint8(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some Result with augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = DataGenerator(batch_size=64,shuffle=False)\nimages,masks = a.__getitem__(0)\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im.squeeze(), cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.axis('off')\nplt.suptitle(\"Chest X-rays(No Augm), Red: Pneumothorax.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some Results with augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = DataGenerator(batch_size=64,augmentations=AUGMENTATIONS_TRAIN,shuffle=False)\nimages,masks = a.__getitem__(0)\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im[:,:,0], cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.axis('off')\nplt.suptitle(\"Chest X-rays, Red: Pneumothorax.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning rate scheduler ( using cosine annealing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CallBackObjects:\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n        self.iteration = 0\n        self.learningRate = []\n\n    def get_callbacks(self, model_prefix='Model'):\n\n        callback_list = [\n            callbacks.ModelCheckpoint(\"./keras.model\",monitor='val_my_iou_metric', mode = 'max', save_best_only=True, verbose=1),\n            swa,\n            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n        ]\n\n        return callback_list\n    \n    def on_train_batch_begin(self,nb_epochs):\n        pass\n    \n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T // self.M))\n        cos_inner /= self.T // self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero / 2 * cos_out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implemening SWA gives a better result"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SWA(keras.callbacks.Callback):\n    \n    def __init__(self, filepath, swa_epoch):\n        super(SWA, self).__init__()\n        self.filepath = filepath\n        self.swa_epoch = swa_epoch \n    \n    def on_train_begin(self, logs=None):\n        self.nb_epoch = self.params['epochs']\n        print('Stochastic weight averaging selected for last {} epochs.'\n              .format(self.nb_epoch - self.swa_epoch))\n        \n    def on_epoch_end(self, epoch, logs=None):\n        \n        if epoch == self.swa_epoch:\n            self.swa_weights = self.model.get_weights()\n            \n        elif epoch > self.swa_epoch:    \n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * \n                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  \n\n        else:\n            pass\n    def on_train_end(self, logs=None):\n        self.model.set_weights(self.swa_weights)\n        print('Final model parameters set to stochastic weight average.')\n        self.model.save_weights(self.filepath)\n        print('Final stochastic averaged weights saved to file.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unet"},{"metadata":{"trusted":true},"cell_type":"code","source":"def down_block(x,filters,kernel_size=(3,3),padding='same',strides=1):\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n    p=keras.layers.MaxPool2D((2,2),(2,2))(c)\n    return c,p\ndef up_block(x,skip,filters,kernel_size=(3,3),padding='same',strides=1):\n    us=keras.layers.UpSampling2D((2,2))(x)\n    concat=keras.layers.concatenate([us,skip],axis=3)\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(concat)\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n    return c\ndef bottleNeck(x,filters,kernel_size=(3,3),padding='same',strides=1):\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n    return c\ndef unet():\n    f = [64,128,256,512,1024]#feature maps, number of filters\n    inputs=keras.layers.Input((image_size,image_size,3))#input to the model\n    p0 = inputs\n    c1,p1 = down_block(p0,f[0])#1->64\n    c2,p2 = down_block(p1,f[1])#64->128\n    c3,p3 = down_block(p2,f[2])#128->256\n    c4,p4 = down_block(p3,f[3])#256->512\n    drop1 = keras.layers.Dropout(0.5)(p4)\n    \n    bn = bottleNeck(drop1,f[4])#512->1024\n    drop2 = keras.layers.Dropout(0.5)(bn)\n\n    u1 = up_block(drop2,c4,f[3])#1024->512\n    u2 = up_block(u1,c3,f[2])#512->256\n    u3 = up_block(u2,c2,f[1])#256->128\n    u4 = up_block(u3,c1,f[0])#128->64\n    \n    outputs_up = keras.layers.Conv2D(2,(3,3),padding=\"same\",activation=\"relu\")(u4)#64->2\n    outputs = keras.layers.Conv2D(1,(1,1),padding=\"same\",activation=\"sigmoid\")(outputs_up)#2->1\n    model = keras.models.Model(inputs,outputs)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"U-net ++ with efficientNet Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = keras.layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = keras.layers.BatchNormalization()(x)\n    if activation == True:\n        x = LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = LeakyReLU(alpha=0.1)(blockInput)\n    x = keras.layers.BatchNormalization()(x)\n    blockInput = keras.layers.BatchNormalization()(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = keras.layers.Add()([x, blockInput])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet import EfficientNetB4\n\ndef UEfficientNet(input_shape=(None, None, 3),dropout_rate=0.1):\n\n    backbone = EfficientNetB4(weights='imagenet',\n                            include_top=False,\n                            input_shape=input_shape)\n    input = backbone.input\n    start_neurons = 8\n\n    conv4 = backbone.layers[342].output\n    conv4 = LeakyReLU(alpha=0.1)(conv4)\n    pool4 = keras.layers.MaxPooling2D((2, 2))(conv4)\n    pool4 = keras.layers.Dropout(dropout_rate)(pool4)\n    \n     # Middle\n    convm = keras.layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = LeakyReLU(alpha=0.1)(convm)\n    \n    deconv4 = keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    deconv4_up1 = keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4)\n    deconv4_up2 = keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up1)\n    deconv4_up3 = keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up2)\n    uconv4 = keras.layers.concatenate([deconv4, conv4])\n    uconv4 = keras.layers.Dropout(dropout_rate)(uconv4) \n    \n    uconv4 = keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n#     uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = LeakyReLU(alpha=0.1)(uconv4)  #conv1_2\n    \n    deconv3 = keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3_up1 = keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n    deconv3_up2 = keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3_up1)\n    conv3 = backbone.layers[154].output\n    uconv3 = keras.layers.concatenate([deconv3,deconv4_up1, conv3])    \n    uconv3 = keras.layers.Dropout(dropout_rate)(uconv3)\n    \n    uconv3 = keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n#     uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n\n    deconv2 = keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    deconv2_up1 = keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n    conv2 = backbone.layers[92].output\n    uconv2 = keras.layers.concatenate([deconv2,deconv3_up1,deconv4_up2, conv2])\n        \n    uconv2 = keras.layers.Dropout(0.1)(uconv2)\n    uconv2 = keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n#     uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n    \n    deconv1 = keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[30].output\n    uconv1 = keras.layers.concatenate([deconv1,deconv2_up1,deconv3_up2,deconv4_up3, conv1])\n    \n    uconv1 = keras.layers.Dropout(0.1)(uconv1)\n    uconv1 = keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n#     uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n    \n    uconv0 = keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = keras.layers.Dropout(0.1)(uconv0)\n    uconv0 = keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n#     uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = keras.layers.Dropout(dropout_rate/2)(uconv0)\n    output_layer = keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = Model(input, output_layer)\n    model.name = 'u-xception'\n\n    return model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uncomment code below to using U-net model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# U_net_model = unet()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uncomment code below to using U-net++ model"},{"metadata":{"trusted":true},"cell_type":"code","source":"U_net_PP_model = UEfficientNet(input_shape=(image_size,image_size,3),dropout_rate=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    if U_net_model:\n        model = U_net_model\n    elif U_net_PP_model:\n        model = U_net_PP_model\n    model.compile(loss=bce_dice_loss,optimizer=\"adam\", metrics=[my_iou_metric])\n    #model.summary()\n    snapshot = CallBackObjects(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-3)\n    if epochs < 5:\n        swa = SWA('./keras_swa.model',1)\n    elif 5<=epochs and epochs<= 10:\n        swa = SWA('./keras_swa.model',(epochs-3))\n    elif epochs <= 20:\n        swa = SWA('./keras_swa.model',(epochs-5))\n    elif epochs > 20:\n        swa = SWA('./keras_swa.model',(epochs-10))\nexcept:\n    print(\"Error: A model need to be selected\")\ntraining_generator = DataGenerator(batch_size=16,augmentations=AUGMENTATIONS_TRAIN,img_size=image_size)\nvalidation_generator = DataGenerator(batch_size=16,train_im_path = val_fn ,\n                                     train_mask_path=val_mask,augmentations=AUGMENTATIONS_TEST,\n                                     img_size=image_size)\n\nhistory = model.fit_generator(generator=training_generator,\n                            validation_data=validation_generator,                            \n                            use_multiprocessing=False,\n                            epochs=epochs,verbose=1,\n                            callbacks=snapshot.get_callbacks())\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plots of Learning curves and change of learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,4))\nplt.subplot(1,3,1)\nplt.plot(history.history['my_iou_metric'][1:])\nplt.plot(history.history['val_my_iou_metric'][1:])\nplt.ylabel('iou')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\n\nplt.title('model IOU')\n\nplt.subplot(1,3,2)\nplt.plot(history.history['loss'][1:])\nplt.plot(history.history['val_loss'][1:])\nplt.ylabel('val_loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\nplt.title('model loss')\ngc.collect()\n\nplt.subplot(1,3,3)\n#plt.plot(list(np.arange(epochs)))\nplt.plot(history.history['lr'])\nplt.yscale('log')\nplt.xlabel('Iteration')\nplt.ylabel('Learning rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using trained model for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fn = glob.glob(path_for_test + '*')\nx_test = [cv2.resize(np.array(Image.open(fn)),(image_size,image_size)) for fn in test_fn]\nx_test = np.array(x_test)\nx_test = np.array([np.repeat(im[...,None],3,2) for im in x_test])\npreds_test = model.predict(x_test,batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some prediction results"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nfor i, idx in enumerate(test_fn[:max_images]):\n    img = x_test[i]\n    pred = preds_test[i].squeeze()\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(img.squeeze(), cmap=\"Greys\")\n    ax.imshow(np.array(np.round(pred > 0.5), dtype=np.float32), alpha=0.5, cmap=\"Reds\")\n    ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generating a submission csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"rles = []\n\nfor p in tqdm_notebook(preds_test):\n    p = p.squeeze()\n    im = cv2.resize(p,(1024,1024))\n    im = im > 0.5\n#     zero out the smaller regions.\n    if im.sum()<1024*2:\n        im[:] = 0\n    im = (im.T*255).astype(np.uint8)  \n    rles.append(mask2rle(im, 1024, 1024))\n\n\nids = [o.split('/')[-1][:-4] for o in test_fn]\nsub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\nsub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsub_df.head()\nsub_df.to_csv('submission.csv', index=False)\nsub_df.tail(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}