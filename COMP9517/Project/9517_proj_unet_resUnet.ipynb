{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n#what can be done next?\n#1. exploit more on loss function\n#2. make unet deeper/wider?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install albumentations > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport os,sys,random,cv2,re\nimport tensorflow as tf\nimport tifffile\nfrom tensorflow import keras\n#from keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom scipy.ndimage.filters import gaussian_filter\nfrom tensorflow import reduce_sum\nfrom tensorflow.keras.backend import pow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\nfrom tensorflow.keras.losses import binary_crossentropy\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nimport skimage.io as io\nimport skimage.transform as trans\nimport matplotlib.pyplot as plt\nimport shutil\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nimage_size = 512\nbatch_size = 2\nh,w = 512,512","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ***** Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test-train split\nimageData = os.listdir(\"../input/images\")\nimageLabel = os.listdir(\"../input/labels\")\n#ensure image and labels correspond\nimageData.sort()\nimageLabel.sort()\ntrainImage,validImage,trainLable,validLabel = train_test_split(imageData,imageLabel,test_size=0.2,shuffle=True,random_state=2)\ndef addPrefix(x):\n    pre = x.split(\"-\")[1][0:3]\n    if(pre == \"vol\"):\n        return \"../input/images/\" + x\n    elif(pre == \"lab\"):\n        return \"../input/labels/\" + x\n    else:\n        return \"Invalid input\"\ntmp = [trainImage,validImage,trainLable,validLabel]\n\ntrainImage = list(map(addPrefix,trainImage))\nvalidImage = list(map(addPrefix,validImage))\ntrainLable = list(map(addPrefix,trainLable))\nvalidLabel = list(map(addPrefix,validLabel))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image Augumentation"},{"metadata":{},"cell_type":"markdown","source":"Elastic Transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n         Convolutional Neural Networks applied to Visual Document Analysis\", in\n         Proc. of the International Conference on Document Analysis and\n         Recognition, 2003.\n\n     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n    \"\"\"\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    shape = image.shape\n    shape_size = shape[:2]\n    \n    # Random affine\n    center_square = np.float32(shape_size) // 2\n    square_size = min(shape_size) // 3\n    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n    M = cv2.getAffineTransform(pts1, pts2)\n    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n\n    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n    dz = np.zeros_like(dx)\n\n    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n\n    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define function to draw a grid\ndef draw_grid(im, grid_size):\n    # Draw grid lines\n    for i in range(0, im.shape[1], grid_size):\n        cv2.line(im, (i, 0), (i, im.shape[0]), color=(255,))\n    for j in range(0, im.shape[0], grid_size):\n        cv2.line(im, (0, j), (im.shape[1], j), color=(255,))\n\n# Load images\nim = cv2.imread(\"../input/images/train-volume00.jpg\", -1)\nim_mask = cv2.imread(\"../input/labels/train-labels00.jpg\", -1)\n# Draw grid lines\ndraw_grid(im, 50)\ndraw_grid(im_mask, 50)\n\n# Merge images into separete channels (shape will be (cols, rols, 2))\n\nim_merge = np.concatenate((im[...,None], im_mask[...,None]), axis=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def elasticTrans(img, msk, batchSize = 2):\n    length = img.shape[1]\n    for i in range(img.shape[0]):\n        im_merge = np.concatenate((img[i], msk[i]), axis=2)\n        im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, \\\n                                       im_merge.shape[1] * 0.08,im_merge.shape[1] * 0.08)\n        img[i] = im_merge_t[..., 0].reshape(length, length, 1)\n        #plt.imshow(img[i].reshape(256,256), 'gray')\n        #plt.show()\n        msk[i] = im_merge_t[..., 1].reshape(length, length, 1)\n    return img, msk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First sample...\n\n%matplotlib inline\n\n# Apply transformation on image\nim_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08, im_merge.shape[1] * 0.08)\n\n# Split image and mask\nim_t = im_merge_t[...,0]\nim_mask_t = im_merge_t[...,1]\n\n# Display result\nplt.figure(figsize = (16,14))\nplt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. 数据增强 Data augmentation的参数\n\ndef saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n    stacked = []\n    for i,item in enumerate(npyfile):\n        img = item[:,:,0].astype('float32')\n        img = np.expand_dims(img,axis=0)\n        if(len(stacked)==0):\n            stacked = img\n        else:\n            stacked = np.vstack((stacked,img))\n    tifffile.imsave(save_path + '/allPredict.tif', stacked)\n        #tifffile.imsave(, tiff_list)\n        #io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n\ndef adjustData(img,mask,flag_multi_class,num_class):\n    if(np.max(img) > 1):\n        #divided by 255 to convert to probability image\n        img = img / 255\n        mask = mask /255\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n    return (img,mask)\n\ndata_gen_args = dict(rotation_range=0.2,\n                    width_shift_range=0.05,\n                    height_shift_range=0.05,\n                    shear_range=0.05,\n                    zoom_range=0.05,\n                    horizontal_flip=True,\n                    fill_mode='reflect')\n\ndef trainGenerator(batch_size,trainImage,trainLable,aug_dict,image_color_mode = \"grayscale\",\n                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (512,512),seed = 1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow(\n        x = np.array([cv2.imread(ele,0).reshape((512,512,1)) for ele in trainImage]),\n        batch_size = batch_size,\n        shuffle = True,\n        seed = seed,\n        save_to_dir = save_to_dir \n    )\n    mask_generator = mask_datagen.flow(\n        x = np.array([cv2.imread(ele,0).reshape((512,512,1)) for ele in trainLable]),\n        batch_size = batch_size,\n        shuffle = True,\n        seed = seed,\n        save_to_dir = save_to_dir \n    )\n\n    train_generator = zip(image_generator, mask_generator)\n#     counter = 0\n    for (img,mask) in train_generator:\n        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n#         if(counter%10 == 0):\n#             img,mask = elasticTrans(img,mask)\n#         counter += 1\n        yield (img,mask)\n        \nmyGene = trainGenerator(batch_size,trainImage,trainLable,data_gen_args,save_to_dir = None)\nmyValid = trainGenerator(batch_size,validImage,validLabel,data_gen_args,save_to_dir = None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **Visualize data augumentation result**"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = myGene.__next__()\nk = 1\nplt.figure(figsize=(15,15))\nfor i in range(2):\n    for j in range(2):\n        plt.subplot(2,2,k)\n        plt.imshow(a[i][j].reshape(512,512),'gray')\n        k+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loss Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred, smooth = 1):\n    return 1- dice_coef(y_true, y_pred, smooth)\n\ndef bce_dice_loss(y_true, y_pred, weight = 1, smooth = 1):\n    '''\n    bce + w*dice loss\n    '''\n    return binary_crossentropy(y_true, y_pred) + weight*dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Define Unet Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"# def down_block(x,filters,kernel_size=(3,3),padding='same',strides=1):\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(x)\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(c)\n#     p=keras.layers.MaxPool2D((2,2),(2,2))(c)\n#     return c,p\n# def up_block(x,skip,filters,kernel_size=(3,3),padding='same',strides=1):\n#     us=keras.layers.UpSampling2D((2,2))(x)\n#     concat=keras.layers.concatenate([us,skip],axis=3)\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(concat)\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(c)\n#     return c\n# def bottleNeck(x,filters,kernel_size=(3,3),padding='same',strides=1):\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(x)\n#     c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu',kernel_initializer = 'he_normal')(c)\n#     return c\n# def Unet():\n#     f = [64,128,256,512,1024]#feature maps, number of filters\n#     inputs=keras.layers.Input((image_size,image_size,1))#input to the model\n#     p0 = inputs\n#     c1,p1 = down_block(p0,f[0])#1->64\n#     c2,p2 = down_block(p1,f[1])#64->128\n#     c3,p3 = down_block(p2,f[2])#128->256\n#     c4,p4 = down_block(p3,f[3])#256->512\n#     drop1 = keras.layers.Dropout(0.5)(p4)\n    \n#     bn = bottleNeck(drop1,f[4])#512->1024\n#     drop2 = keras.layers.Dropout(0.5)(bn)\n\n#     u1 = up_block(drop2,c4,f[3])#1024->512\n#     u2 = up_block(u1,c3,f[2])#512->256\n#     u3 = up_block(u2,c2,f[1])#256->128\n#     u4 = up_block(u3,c1,f[0])#128->64\n    \n#     outputs_up = keras.layers.Conv2D(2,(3,3),padding=\"same\",activation=\"relu\",kernel_initializer = 'he_normal')(u4)#64->2\n#     outputs = keras.layers.Conv2D(1,(1,1),padding=\"same\",activation=\"sigmoid\")(outputs_up)#2->1\n#     print(\"output\",outputs.shape)\n#     model = keras.models.Model(inputs,outputs)\n#     return model\n\n\n\n\n\n\n\ndef unet(pretrained_weights = None,input_size = (512, 512, 1)):\n    inputs = keras.layers.Input(input_size)\n    conv1 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = keras.layers.Dropout(0.5)(conv4)\n    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = keras.layers.Dropout(0.5)(conv5)\n\n    up6 = keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = keras.layers.concatenate([drop4,up6], axis = 3)\n    conv6 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = keras.layers.concatenate([conv3,up7], axis = 3)\n    conv7 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = keras.layers.concatenate([conv2,up8], axis = 3)\n    conv8 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = keras.layers.concatenate([conv1,up9], axis = 3)\n    conv9 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = keras.layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = keras.layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = keras.models.Model(inputs,conv10)\n\n    model.compile(optimizer = Adam(lr = 1e-4), loss = [dice_loss], metrics = ['accuracy', dice_coef])\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = focal_loss(gamma=2,alpha=0.6), metrics = ['accuracy', dice_coef])\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = focal_dice_loss, metrics = ['accuracy', dice_coef])\n    \n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ResUnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def bn_act(x, act=True):\n#     'batch normalization layer with an optinal activation layer'\n#     x = tf.keras.layers.BatchNormalization()(x)\n#     if act == True:\n#         x = tf.keras.layers.Activation('relu')(x)\n#     return x\n# def conv_block(x, filters, kernel_size=3, padding='same', strides=1):#BN + RELU + CONV\n#     'convolutional layer which always uses the batch normalization layer'\n#     conv = bn_act(x)\n#     conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n#     return conv\n# def stem(x, filters, kernel_size=3, padding='same', strides=1):\n#     conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n#     conv = conv_block(conv, filters, kernel_size, padding, strides)\n#     shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n#     shortcut = bn_act(shortcut, act=False)\n#     output = Add()([conv, shortcut])\n#     return output\n# def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n#     res = conv_block(x, filters, 3, padding, strides)\n#     res = conv_block(res, filters, 3, padding, 1)\n#     shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n#     shortcut = bn_act(shortcut, act=False)\n#     output = Add()([shortcut, res])\n#     return output\n# def upsample_concat_block(x, xskip):\n#     u = UpSampling2D((2,2))(x)\n#     c = Concatenate()([u, xskip] )\n#     return c\n# def ResUNet(img_size):\n#     f = [16, 32, 64, 128, 256]\n#     inputs = Input((img_size, img_size, 1))\n    \n#     ## Encoder\n#     e0 = inputs\n#     e1 = stem(e0, f[0])\n#     e2 = residual_block(e1, f[1], strides=2)\n#     e3 = residual_block(e2, f[2], strides=2)\n#     e4 = residual_block(e3, f[3], strides=2)\n#     e5 = residual_block(e4, f[4], strides=2)\n    \n#     ## Bridge\n#     b0 = conv_block(e5, f[4], strides=1)\n#     b1 = conv_block(b0, f[4], strides=1)\n    \n#     ## Decoder\n#     u1 = upsample_concat_block(b1, e4)\n#     d1 = residual_block(u1, f[4])\n    \n#     u2 = upsample_concat_block(d1, e3)\n#     d2 = residual_block(u2, f[3])\n    \n#     u3 = upsample_concat_block(d2, e2)\n#     d3 = residual_block(u3, f[2])\n    \n#     u4 = upsample_concat_block(d3, e1)\n#     d4 = residual_block(u4, f[1])\n    \n#     outputs = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n#     model = tf.keras.models.Model(inputs, outputs)\n#     return model\n\n\n# adam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unet"},{"metadata":{"trusted":true},"cell_type":"code","source":"...\n#model = Unet()\n# class LossHistory(Callback):\n#     def __init__(self, epochs):\n#         self.epochs = epochs\n        \n#     def on_train_begin(self, logs={}):\n#         self.losses = []\n#         self.acc_logs = []\n#         self.history_logs = []\n#         self.check = 0\n#         self.lrr = 0.001\n#         print('Training Start.....')\n\n#     def on_train_end(self, logs={}):\n#         average_acc = sum(self.acc_logs)/len(self.acc_logs)\n#         print(\"Average accury over {0} epochs is {1}\".format(len(self.acc_logs),average_acc))\n#         print(\"Training Done!\")\n        \n#     def on_train_batch_begin(self, batch, logs=None):\n#         pass\n\n#     def on_train_batch_end(self, batch, logs=None):\n#         pass\n    \n#     def on_epoch_begin(self, epoch,logs=None):\n#         #print(K.get_value(self.model.optimizer.lr))\n#         pass\n\n#     def on_epoch_end(self, epoch, logs=None):\n#         if(len(self.history_logs) >= 2):\n#             curren_acc = round(float(logs.get('acc')),3)\n#             last_acc = round(float(self.losses[-1]),3)\n#             #print(\" current is {0} and last is {1}\".format(curren_acc,last_acc))\n#             if(curren_acc == last_acc):\n#                 self.check += 1\n#             elif(curren_acc > last_acc):\n#                 self.check = 0\n#         #print(\" {0} many bad attemps\".format(history_callback.check))\n#         self.losses.append(logs.get('acc'))\n#         self.acc_logs.append(logs.get('acc'))\n#         self.history_logs.append(len(self.losses))\n#         self.lrr = step_decay(self.lrr)\n#         self.model.optimizer.lr = self.lrr\n        \n# history_callback=LossHistory(50)\n# def step_decay(learningRate):\n#     if history_callback.check >= 5:\n#         lrate=learningRate * 0.1\n#         momentum=0.8\n#         decay_rate=2e-6\n#         print(\" learning rate dropped to \",lrate)\n#         return lrate\n#     else:\n#         return 0.001\n# lrate=LearningRateScheduler(step_decay)           \n\n# model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"acc\"])\n# model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[history_callback])#,validation_steps=valid_steps)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = unet()\n#model = ResUNet(512)\n\nmodel.compile(optimizer = Adam(lr = 1e-4), loss = bce_dice_loss, metrics = ['accuracy', dice_coef])\n\nmodel_checkpoint = keras.callbacks.ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\nprint('number of train ',len(trainImage))\nprint('number of valid ',len(validImage))\ntrainStep = len(trainImage)//batch_size\nvalidStep = len(validImage)//batch_size\nhistory = model.fit_generator(myGene,steps_per_epoch=trainStep,epochs=80,callbacks=[model_checkpoint],\\\n                   validation_data = myValid, validation_steps = validStep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# opt = keras.optimizers.Adam(lr=0.001)\n# #model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[\"acc\"])#metrics=[dsc]\n# model.compile(optimizer=opt, loss=bce_dice_loss,  metrics = ['accuracy', dice_coef])#metrics=[dsc]\n# #model.summary()\n\n# trainStep = len(trainImage)//batch_size\n# validStep = len(validImage)//batch_size\n# history = model.fit_generator(myGene,steps_per_epoch=trainStep*2,epochs=200,validation_data=myValid,validation_steps=validStep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_final_history(history):\n    fig= plt.figure(figsize=(10,10))\n    plt.title('Loss')\n    plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    plt.legend()\n    fig= plt.figure(figsize=(10,10))\n    plt.title('Acc')\n    plt.plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    plt.legend()\n    fig= plt.figure(figsize=(10,10))\n    plt.title('Dice_coef')\n    plt.plot(history.epoch, history.history[\"dice_coef\"], label=\"Train acc\")\n    plt.plot(history.epoch, history.history[\"val_dice_coef\"], label=\"Validation acc\")\n    plt.legend()\nshow_final_history(history)\nprint(\"Validation Accuracy: \" + str(history.history['val_acc'][-1:]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. test model and zip output**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nimport cv2\n\ndirectory = os.listdir(\"../input/images/\")\ndirectory.sort()\n#create output folder\nif not os.path.exists(\"./output\"):\n    os.makedirs(\"./output\")\n\ndef testGenerator(test_path,target_size = (512,512)):\n    for i in test_path:\n        i = \"../input/images/\" + i\n        img = cv2.imread(i,0)\n        img = img / 255\n\n        img = trans.resize(img,target_size)\n        img = np.reshape(img,img.shape+(1,))\n        img = np.reshape(img,(1,)+img.shape)\n        yield img\n        \ntestGene = testGenerator(directory)\nresult = model.predict_generator(testGene,steps = len(directory),verbose=1)\n\nsaveResult(\"./output\",result)\nmyoutputDir = \"./output\"\n\nwith ZipFile(\"./testOut.zip\",\"w\") as zip:\n    for file in os.listdir(myoutputDir):\n        zip.write(\"./output/\" + file)\n        \nprint(list(zip.infolist()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.shape\nplt.figure(0)\nplt.imshow(result[0,:,:,0],'gray')\nplt.show","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}