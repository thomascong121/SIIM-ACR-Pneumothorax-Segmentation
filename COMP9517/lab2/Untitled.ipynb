{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of descriptor is:  5258\n",
      "descriptor values are: \n",
      " [[ 31.  11.  13. ...   4.  15.   1.]\n",
      " [  0.   0.   1. ...   0.   0.   1.]\n",
      " [  1.  45.   2. ...   0.   0.   4.]\n",
      " ...\n",
      " [ 29.   1.   1. ...   1.   0.  17.]\n",
      " [  3.   2.   1. ...   2.   7.   2.]\n",
      " [ 56.   3.   0. ...  81. 125.  86.]]\n",
      "1/4 is  1314\n",
      "kp1 number is  1321\n",
      "kp2 number is  1293\n",
      "kp is same as kp1 ?  False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'rotator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b82b9cfcbdc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mangle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mrotator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mimg_rotate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'rotator' object is not callable"
     ]
    }
   ],
   "source": [
    "# Template for computing SIFT features\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class SiftDetector():\n",
    "    def __init__(self, norm=\"L2\", params=None):\n",
    "        self.detector=self.get_detector(params)\n",
    "        self.norm=norm\n",
    "\n",
    "    def get_detector(self, params):\n",
    "        if params is None:\n",
    "            params={}\n",
    "            params[\"n_features\"]=0\n",
    "            params[\"n_octave_layers\"]=3\n",
    "            params[\"contrast_threshold\"]=0.04\n",
    "            params[\"edge_threshold\"]=10\n",
    "            params[\"sigma\"]=1.6\n",
    "\n",
    "        detector = cv2.xfeatures2d.SIFT_create(\n",
    "                nfeatures=params[\"n_features\"],\n",
    "                nOctaveLayers=params[\"n_octave_layers\"],\n",
    "                contrastThreshold=params[\"contrast_threshold\"],\n",
    "                edgeThreshold=params[\"edge_threshold\"],\n",
    "                sigma=params[\"sigma\"])\n",
    "\n",
    "        return detector\n",
    "class rotator():\n",
    "    def __init__(self,image,angle,params=None):\n",
    "        self.image = image\n",
    "        self.angle = angle\n",
    "        self.rotator = self.rotate(self.image,self.angle,params)\n",
    "\n",
    "    def rotate(self,image, angle, params):\n",
    "        # 获取图像尺寸\n",
    "        (h, w) = image.shape[:2]\n",
    "        # 若未指定旋转中心，则将图像中心设为旋转中心\n",
    "        if(params is None):\n",
    "            center = (w / 2, h / 2)\n",
    "            scale = 1\n",
    "        else:\n",
    "            center = params[\"center\"]\n",
    "            scale = params[\"scale\"]\n",
    "\n",
    "        # 执行旋转\n",
    "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "     \n",
    "        # 返回旋转后的图像\n",
    "        return rotated\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Read the colour image\n",
    "    img = cv2.imread('NotreDame.jpg')\n",
    "    # For task 2 only, rotate the image by 45 degrees\n",
    "    rotator = rotator(img,-45)\n",
    "    img_rotate = rotator.rotator\n",
    "\n",
    "    # 2. Convert image to greyscale\t\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray2= cv2.cvtColor(img_rotate,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 3. Initialise SIFT detector (with varying parameters)\n",
    "    sift = SiftDetector().get_detector(None)\n",
    "    \n",
    "    # 4. Detect and compute SIFT features\n",
    "    kp = sift.detect(gray,None)\n",
    "    \n",
    "\n",
    "    # 5. Visualise detected keypoints on the colour image \n",
    "    # img_1=cv2.drawKeypoints(img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # cv2.imwrite('sift_keypoints.jpg',img_1)\n",
    "\n",
    "    # 6. compute sift key points and descriptor\n",
    "    kp, des = sift.detectAndCompute(gray,None)\n",
    "    print(\"number of descriptor is: \",len(des))\n",
    "    print(\"descriptor values are: \\n\", des)\n",
    "    # to reduce the number of key point to 1/4\n",
    "    n_keypoints = len(des)//4\n",
    "    print(\"1/4 is \",n_keypoints)\n",
    "    sift = SiftDetector().get_detector({\"n_features\":0,\n",
    "            \"n_octave_layers\":3,\n",
    "            \"contrast_threshold\":0.1,\n",
    "            \"edge_threshold\":8,\n",
    "            \"sigma\":1.6})\n",
    "    kp1 = sift.detect(gray,None)\n",
    "    kp2 = sift.detect(gray2,None)\n",
    "    print(\"kp1 number is \", len(kp1))\n",
    "    print(\"kp2 number is \", len(kp2))\n",
    "    print(\"kp is same as kp1 ? \",kp1==kp)\n",
    "\n",
    "    cv2.drawKeypoints(img,kp1,img)#,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    cv2.drawKeypoints(img_rotate,kp2,img_rotate)#,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    cv2.imwrite('sift_keypoints_less.jpg',img)\n",
    "    cv2.imwrite('sift_keypoints_less_part2.jpg',img_rotate)\n",
    "\n",
    "\n",
    "    #extra......\n",
    "    for angle in range(0,-180,-45):\n",
    "        rotator = rotator(img,angle)\n",
    "        img_rotate = rotator.rotator\n",
    "        \n",
    "        gray2= cv2.cvtColor(img_rotate,cv2.COLOR_BGR2GRAY)\n",
    "        sift = SiftDetector().get_detector({\"n_features\":0,\n",
    "                \"n_octave_layers\":3,\n",
    "                \"contrast_threshold\":0.1,\n",
    "                \"edge_threshold\":8,\n",
    "                \"sigma\":1.6})\n",
    "        kp1 = sift.detect(gray2,None)\n",
    "        cv2.drawKeypoints(img_rotate,kp1,img_rotate)\n",
    "        cv2.imwrite('degree {0}.jpg'.format(angle),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
